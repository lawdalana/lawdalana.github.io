---
title : DigestPaper - Can we Retrieve Everything All at Once
notetype : feed
date : 07-02-2025
---

## Source: [Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method](https://arxiv.org/abs/2501.18539)


### Intro
#### Problem
- ในโลกความเป็นจริงการจะตอบคำถามที่เป็น Open-domain จะต้องใช้ข้อมูลจากหลายๆส่วนรวมเข้าด้วยกัน + ขั้นตอนที่ยุ่งยากเพื่อเอาคำตอบออกมา

#### Solution V1
- แต่ LLM ก็ทำให้ขั้นตอนในการตอบคำถามนั้นง่ายขึ้น ซึ่งงานส่วนใหญ่จะเป็นการพัฒนา model retrieval ให้เหมาะกับคำถามยากๆเท่านั้น

#### Solution V2
- ต่อมามีการพัฒนา LLM ให้ตอบคำถามยากๆ โดยการแตกคำถามที่ซับซ้อนออกเป็น คำถามง่ายๆ หลายคำถาม และนำแต่ละคำถามไปค้นหาข้อมูลที่เกี่ยวข้อง แล้วจึงสรุปออกมา 
- แต่ LLM ก็ยังไม่สามารถรู้ได้ว่ามีข้อมูลที่ใช้ได้อื่นๆอีกไหม

#### Solution V3
- การพัฒนาในขั้นต่อมาก็คือการให้ LLM สามารถ interact กับ data collection ได้ตรงๆ ซึ่งจะทำให้ LLM สามารถ explore ได้เองว่ามีข้อมูลอะไรอยู่บ้าง แล้วดึงมาเช็คเอง

#### Solution V3.1
- ซึ่งตัวที่สามารถทำได้ดีคือ LLM ตัวที่เป็น reasoning and acting หรือก็คือ LLM จะดึงข้อมูลไปเรื่อยๆ และคอยเช็คว่าข้อมูลที่ได้มาเพียงพอที่จะต้อบคำถามที่ซับซ้อนหรือยัง ถ้ายัง ก็จะไปตัดสินใจว่าจะดึงข้อมูลตรงส่วนมาเพิ่ม
- วิธีนี้เป็นวิธีที่ดี แต่ตัว LLM ก็ต้องคอยไปดึงอยู่เรื่อยๆ เพราะต้อง explore ซึ่งจะเปลือง time and cost
- LLM เมื่อมีการวนหลายๆรอบ จะเกิดปัญหา [reasoning derailment] ส่งผลให้ตอบผิด

#### Solution V4 (ARM: An Alignment-Oriented LLM-based Retrieval Method)
- ARM เป็นวิธีการเรียกค้นข้อมูลที่ เน้นการจัดแนวข้อมูลให้เหมาะสมกับโครงสร้างของชุดข้อมูล ทำให้สามารถดึงข้อมูลทั้งหมดที่จำเป็นได้ในครั้งเดียว
- ARM ผสานการใช้เหตุผลเกี่ยวกับความสัมพันธ์ของข้อมูล ช่วยให้สามารถดึงข้อมูลที่เกี่ยวข้องโดยเชื่อมโยงข้อมูลที่อาจไม่ได้ถูกกล่าวถึงโดยตรงในคำถาม

![Summary approach ARM](/assets/img/Other/Knowledge/ARM_RAG.avif) 
---

### Overview

- ARM ซึ่งเป็นแนวทางการเรียกค้นข้อมูลที่สอดคล้องกับโครงสร้างของชุดข้อมูล โดยใช้แนวคิด retrieving while generating เพื่อให้ LLM สามารถใช้ความสามารถในการให้เหตุผลร่วมกับการเรียกค้นข้อมูล (รวมกระบวนการเรียกค้นและการใช้เหตุผลเข้าด้วยกันเป็นกระบวนการเดียว โดยอาศัยข้อมูลจากโครงสร้างของข้อมูลที่มีอยู่)
- ปัญหาหลักของการเรียกค้นแบบเดิมคือ LLM อาจสามารถระบุข้อมูลที่จำเป็นได้ แต่ไม่สามารถเชื่อมโยงข้อมูลเข้ากับแหล่งข้อมูลที่มีอยู่จริง
- ARM เป็นกระบวนที่มีหลายขั้นตอน โดยแต่ละขั้นตอนมุ่งเน้นไปที่การจัดแนวข้อมูล (alignment) กับชุดข้อมูลที่มีอยู่
- ในขั้นตอนแรก information alignment เพื่อกำหนดข้อมูลหลักที่จำเป็นต่อคำถาม โดยอาศัยการแมปคีย์เวิร์ดกับ N-grams จากชุดข้อมูล
- ขั้นตอนต่อมาเป็น structure alignment ซึ่งช่วยระบุความเชื่อมโยงระหว่างข้อมูลต่างๆ ที่ถูกเรียกค้น พร้อมทั้งเติมเต็มข้อมูลที่อาจขาดหายไป
- สุดท้ายใช้ self-verification เพื่อให้ LLM ตรวจสอบและคัดกรองข้อมูลที่เกี่ยวข้องมากที่สุด และรวมผลลัพธ์จากหลายแนวทางผ่านกระบวนการ beam search เพื่อให้ได้ชุดข้อมูลที่เหมาะสมที่สุดสำหรับการตอบคำถาม
---

### Methodology
#### Indexing (ขั้นเตรียม Documents)
- เรารวมแหล่งข้อมูลทุกประเภท (เช่น ตารางและข้อความ) ให้อยู่ในรูปแบบของ textual data objects และทำการแบ่งข้อมูลเป็นชิ้นเล็กๆ (chunking)
- ข้อมูลแต่ละส่วนจะมีหัวข้อ concatenation ติดไปด้วย ถ้าเป็นตาราง ก็จะมีคำอธิบายเพิ่มเข้าไปอีก
- แต่ละ chunk จะถูกแปลงเป็น embedding และ สร้าง Index ด้วย N-grams (1-3 Grams) เพื่อใช้ในการค้นหาข้อมูลที่เกี่ยวข้องได้รวดเร็วขึ้น
- ทั้ง embedding และ N-Grams จะช่วยให้ guide LLM ให้ค้นข้มูลว่าตรงไหนใช้ตอบคำถามได้
---

#### Alignment (ขั้น Generate Answer)
#### Information Alignment
Information Alignment เป็นขั้นตอนแรกของ ARM ที่มุ่งเน้นการระบุข้อมูลสำคัญที่จำเป็นสำหรับการตอบคำถาม โดยการจับคู่ข้อมูลที่เกี่ยวข้องจาก ชุดข้อมูล (data collection) ให้ตรงกับคำถามของผู้ใช้

`IA Step 1: Keyword Extraction (การแยกคีย์เวิร์ดจากคำถาม)`
```
เป้าหมาย: แยกคำสำคัญ (key information) ออกจากคำถาม เพื่อระบุสิ่งที่ต้องค้นหา
1. LLM ถูกตั้งค่าให้ แยกคำหลัก ออกจากคำถาม เช่น ชื่อบุคคล, สถานที่, ค่าตัวเลข, และคำหลักที่มีความหมายเฉพาะ
2. ตัวอย่างเช่น คำถาม "What is the highest eligible free rate for K-12 students in the schools in the most populous county in California?"
    - คีย์เวิร์ดที่สำคัญ: "highest eligible free rate", "K-12 students", "most populous county", "California"
```

`IA Step 2: N-gram Matching (จับคู่คีย์เวิร์ดกับข้อมูลในชุดข้อมูล)`
```
เป้าหมาย: จับคู่คำที่แยกออกมากับ N-grams ที่อยู่ในชุดข้อมูล
1. แต่ละข้อมูลในฐานข้อมูลจะถูกแปลงเป็น N-grams (n=1 ถึง n=3) เพื่อสร้างดัชนีของคำที่ปรากฏ
2. คำหลักที่ได้จาก Step 1 จะถูกนำมา เปรียบเทียบกับ N-grams ที่ถูกจัดเก็บไว้ในฐานข้อมูล
3. หากคำหลักของคำถามไม่มีอยู่ในฐานข้อมูลแบบตรงตัว จะใช้ synonyms และการ rephrasing เพื่อหาคำที่ใกล้เคียงที่สุด
```

`IA Step 3: Constrained Beam Decoding (ใช้ LLM สร้างชุดข้อมูลที่ตรงกับคำถาม)`
```
เป้าหมาย: ให้ LLM ใช้คำที่แมปกับ N-grams และเลือกข้อมูลที่เกี่ยวข้องมากที่สุด
1. ใช้ Constrained Beam Decoding (LIB transformers support this feature)บังคับให้ LLM เลือกคำที่มีอยู่ในฐานข้อมูล แทนที่จะสร้างข้อความใหม่ เมื่อเจอ token "("
2. Always Maintain top list of N-grams 
3. กระบวนการจะทำงานจนกว่าโมเดลจะค้นพบ คำหรือข้อมูลที่เชื่อมโยงกับคำถามได้ครบถ้วน เมื่อเจอ token ")"
4. ข้อมูลที่เลือกจะถูกนำไปใช้เป็น input สำหรับขั้นตอนต่อไป (Structure Alignment)
5. final_score = weight(ใช้ BM25 คำนวนคะแนน N-Grams) + weight(embedding similarity)  
```
---

#### Structure Alignment
Structure Alignment เป็นขั้นตอนที่ สอง ใน ARM ซึ่งช่วยจัดโครงสร้างข้อมูลที่ถูกเรียกค้นให้เหมาะสมกับคำถาม เพื่อให้มั่นใจว่า
- ข้อมูลที่ถูกเรียกค้นมีครบทุกส่วนที่จำเป็น
- ข้อมูลที่ดึงมาสามารถเชื่อมโยงกันได้จริง (โดยอาจต้องมีตารางเชื่อมต่อหรือข้อมูลกลางที่ช่วยให้คำตอบสมบูรณ์)
- ลดข้อมูลที่ซ้ำซ้อนหรือไม่จำเป็น เพื่อให้การเรียกค้นมีประสิทธิภาพมากขึ้น

`SA Step 1: Identifying Missing or Redundant Data (ระบุข้อมูลที่ขาดหรือซ้ำซ้อน)`
```
เป้าหมาย: คัดกรองว่าข้อมูลที่ถูกเรียกค้นมา ยังขาดหรือมีส่วนเกินหรือไม่
1. ตรวจสอบว่า ข้อมูลทั้งหมดที่จำเป็นสำหรับการตอบคำถามมีอยู่หรือไม่
2. ตรวจจับ ข้อมูลที่ซ้ำซ้อน เช่น บทความที่ให้ข้อมูลเหมือนกัน หรือ ตารางที่มีข้อมูลซ้ำกัน
3. ค้นหาว่าจำเป็นต้องใช้ bridging tables หรือ bridging entities เพื่อเชื่อมโยงข้อมูลที่เกี่ยวข้องหรือไม่
```

`SA Step 2: Establishing Data Connections (สร้างความเชื่อมโยงของข้อมูล)`
```
เป้าหมาย: จัดโครงสร้างว่าข้อมูลแต่ละชิ้นมีความเกี่ยวข้องกันอย่างไร
1. ใช้ external solver เพื่อตรวจสอบว่าข้อมูลที่ดึงมา สามารถเชื่อมโยงกันได้หรือไม่
2. ค้นหาว่า ข้อมูลใดที่เป็น "bridging entity" ที่จำเป็นต้องใช้
3. ใช้วิธีการ Mixed-Integer Programming (MIP) เพื่อคำนวณว่าส่วนไหนควรจะถูกเก็บไว้และส่วนไหนควรถูกตัดออก
```

`SA Step 3: Optimizing Selection with MIP (การเลือกข้อมูลที่เหมาะสมโดยใช้ Mixed-Integer Programming - MIP)`
```
เป้าหมาย: เลือกข้อมูลที่ดีที่สุดสำหรับการตอบคำถามโดยใช้ ตัวแปรคณิตศาสตร์และการเพิ่มประสิทธิภาพ
1. ใช้ Relevance Score คำนวณว่าข้อมูลแต่ละชิ้นเกี่ยวข้องกับคำถามมากแค่ไหน
2. ใช้ Compatibility Score คำนวณว่าข้อมูลสองชุดสามารถเชื่อมโยงกันได้หรือไม่
3. ใช้ MIP Solver คำนวณและเลือก k ชิ้นของข้อมูลที่ดีที่สุด เพื่อตอบคำถาม
```

![MIP](/assets/img/Other/Knowledge/MIP.avif) 
![MIP_R](/assets/img/Other/Knowledge/MIP_R.avif) 
![MIP_C](/assets/img/Other/Knowledge/MIP_C.avif) 



---

#### Self-Verification and Aggregation: Ensuring Accurate and Reliable Outputs
Self-Verification and Aggregation เป็นขั้นตอนสุดท้ายของ ARM ที่ช่วยให้ LLM ตรวจสอบความถูกต้องของข้อมูล ที่ถูกเรียกค้นมา และ รวมผลลัพธ์ที่ดีที่สุดจากหลายแนวทาง เพื่อสร้างคำตอบที่มีความแม่นยำสูงสุด

`SV Step 1: Draft Injection (นำเสนอร่างข้อมูลให้ LLM)`
```
เป้าหมาย: ให้ LLM ได้รับข้อมูลที่ถูกดึงมา ในรูปแบบที่ถูกจัดโครงสร้างแล้ว และบังคับให้โมเดลเลือกเฉพาะข้อมูลที่เกี่ยวข้องจริงๆ
1. นำเสนอข้อมูลในรูปแบบที่เป็นโครงสร้าง (Serialized Format) 
นำข้อมูลจาก Structure Alignment มาทำให้เป็นข้อความที่ LLM เข้าใจง่าย เช่น ตาราง, รายการ, หรือข้อความ
2. บังคับให้ LLM ใช้ข้อมูลจากร่างข้อมูล (Constraint Decoding)
ใช้ Constrained Beam Decoding เพื่อให้ LLM เลือกคำตอบจากข้อมูลที่ให้มาเท่านั้น ห้ามสร้างข้อความใหม่เอง
3. ระบุความสัมพันธ์ของข้อมูล
ถ้ามีการเชื่อมโยงระหว่างข้อมูล เช่น สองตารางที่ต้องใช้ร่วมกัน โมเดลต้องพิจารณาว่าข้อมูลนี้เกี่ยวข้องจริงหรือไม่
```

`SV Step 2: Self-Verification (ให้ LLM ตรวจสอบความถูกต้องของข้อมูล)`
```
เป้าหมาย: ให้ LLM ตรวจสอบว่า ข้อมูลที่เลือกมาตรงกับคำถามหรือไม่ และ ข้อมูลที่เลือกมาสามารถเชื่อมโยงกันได้จริงหรือไม่
1. ตรวจสอบว่าแต่ละส่วนของคำถามมีคำตอบที่ถูกต้องหรือไม่
ถ้าคำถามมีหลายองค์ประกอบ (เช่น รายได้ + CEO) โมเดลต้องยืนยันว่าได้ดึงข้อมูลที่ถูกต้องมาครบ
2. ตรวจสอบว่าข้อมูลที่ถูกเลือกเป็นข้อมูลที่สามารถเชื่อมโยงกันได้หรือไม่
ถ้ามีข้อมูลหลายชุด (ตาราง, บทความ) โมเดลต้องแน่ใจว่าข้อมูลพวกนี้มีความเกี่ยวข้องกัน
3. ใช้ Constraint Decoding เพื่อป้องกันการเปลี่ยนแปลงข้อมูลจากต้นฉบับ
LLM ต้องเลือกคำตอบจากข้อมูลที่ให้มาเท่านั้น และไม่สามารถ "เดา" คำตอบเอง
```

`SV Step 3: Aggregation Through Confidence Scoring (รวมผลลัพธ์ที่ดีที่สุด)`
```
เป้าหมาย: เลือกข้อมูลที่ดีที่สุดจากผลลัพธ์ที่ได้จาก Self-Verification โดยใช้ คะแนนความมั่นใจ (Confidence Score)
1. ใช้ Beam Search เพื่อสร้างหลายทางเลือกของการเรียกค้นข้อมูล
LLM อาจให้คำตอบที่แตกต่างกันเล็กน้อยจากการเรียกค้นข้อมูล ใช้ Top-N beams เพื่อเลือกผลลัพธ์ที่ดีที่สุด
2. ให้คะแนนข้อมูลแต่ละชุดโดยพิจารณา
- ความสอดคล้องกับคำถาม → ข้อมูลที่มีคำตอบครบทุกส่วนจะได้คะแนนสูงกว่า
- ความมั่นใจของโมเดล (Logit Score) → ข้อมูลที่โมเดลมั่นใจจะได้รับคะแนนสูงขึ้น
- จำนวนครั้งที่ปรากฏในหลาย beams → ข้อมูลที่ถูกเลือกบ่อยที่สุดถือว่าน่าเชื่อถือ
3. ใช้ Weighted Voting เพื่อเลือกคำตอบสุดท้าย
- แต่ละข้อมูลที่ถูกเลือกมี "คะแนนโหวต"
- ข้อมูลที่ได้รับโหวตมากที่สุดและมีความมั่นใจสูงสุดจะถูกเลือกเป็นคำตอบ
```
---


![Example ARM](/assets/img/Other/Knowledge/example.avif) 

### Experiment and Result


![Table1](/assets/img/Other/Knowledge/table1.avif) 
![Table2](/assets/img/Other/Knowledge/table2.avif) 
![Table3](/assets/img/Other/Knowledge/table3.avif) 
![Result1](/assets/img/Other/Knowledge/result1.avif) 
![Relevant_techniqe](/assets/img/Other/Knowledge/relevant_techniqe.avif) 

...